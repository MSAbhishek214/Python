{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Advanced Natural Language Processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "raw",
   "source": [
    "4-1. Extracting Noun Phrases"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#Import libraries\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "# try:\n",
    "#     _create_unverified_https_context = ssl._create_unverified_context\n",
    "# except AttributeError:\n",
    "#     pass\n",
    "# else:\n",
    "#     ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "# nltk.download()\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "#Extract noun\n",
    "blob = TextBlob(\"John is learning natural language processing\")\n",
    "for np in blob.noun_phrases:\n",
    "    print(np)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n",
      "john\n",
      "natural language processing\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "raw",
   "source": [
    "4-2. Finding Similarity Between Texts"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "documents = (\n",
    "\"I like NLP\",\n",
    "\"I am exploring NLP\",\n",
    "\"I am a beginner in NLP\",\n",
    "\"I want to learn NLP\",\n",
    "\"I like advanced NLP\"\n",
    ")\n",
    "\n",
    "#Import libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "tfidf_matrix.shape\n",
    "\n",
    "#output\n",
    "(5, 10)\n",
    "\n",
    "#compute similarity for first sentence with rest of the sentences\n",
    "cosine_similarity(tfidf_matrix[0:1],tfidf_matrix)\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.        , 0.17682765, 0.14284054, 0.13489366, 0.68374784]])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "raw",
   "source": [
    "4-3 Tagging Part of Speech "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "text= \"I love NLP and I will learn NLP in 2 month\"\n",
    "\n",
    "# Importing necessary packages and stopwords\n",
    "import nltk \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize \n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "# Tokenize the text\n",
    "tokens = sent_tokenize(text) \n",
    "\n",
    "#Generate tagging for all the tokens using loop\n",
    "for i in tokens: \n",
    "    words = nltk.word_tokenize(i) \n",
    "    words = [w for w in words if not w in stop_words]  \n",
    "    #  POS-tagger.  \n",
    "    tags = nltk.pos_tag(words) \n",
    "\n",
    "tags\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('love', 'VBP'),\n",
       " ('NLP', 'NNP'),\n",
       " ('I', 'PRP'),\n",
       " ('learn', 'VBP'),\n",
       " ('NLP', 'RB'),\n",
       " ('2', 'CD'),\n",
       " ('month', 'NN')]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "raw",
   "source": [
    "4-4. Extract Entities From Text"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sent = \"John is studying at Stanford University in California\"\n",
    "\n",
    "#import libraries\n",
    "import nltk\n",
    "from nltk import ne_chunk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "#NER\n",
    "ne_chunk(nltk.pos_tag(word_tokenize(sent)), binary=False)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "raw",
   "source": [
    "4-5. Carrying Out Sentiment Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "review = \"I like this phone. screen quality and camera clarity is really good.\"\n",
    "review2 = \"This tv is not good. Bad quality, no clarity, worst experience\"\n",
    "\n",
    "#import libraries\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "\n",
    "#now lets look at the sentiment of review2\n",
    "blob = TextBlob(review2)\n",
    "blob.sentiment\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.6833333333333332, subjectivity=0.7555555555555555)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#TextBlob has a pre trained sentiment prediction model\n",
    "blob = TextBlob(review)\n",
    "blob.sentiment"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.7, subjectivity=0.6000000000000001)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "raw",
   "source": [
    "4-9. Converting speech to text."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "#import library\n",
    "import speech_recognition as sr\n",
    "\n",
    "# Initialize recognizer class (for recognizing the speech)\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Reading Audio file as source\n",
    "# listening the audio file and store in audio_text variable\n",
    "\n",
    "with sr.AudioFile('male.wav') as source:\n",
    "    \n",
    "    audio_text = r.listen(source)\n",
    "    \n",
    "# recoginize_() method will throw a request error if the API is unreachable, hence using exception handling\n",
    "    try:\n",
    "        \n",
    "        # using google speech recognition\n",
    "        text = r.recognize_google(audio_text)\n",
    "        print('Converting audio transcripts into text ...')\n",
    "        print(text)\n",
    "     \n",
    "    except:\n",
    "         print('Sorry.. run again...')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converting audio transcripts into text ...\n",
      "summary the sides to break it therefore the you keep adequate coverage the works of places to save money baby is taking longer to getting squared away then the bank was expected during the life event company in AVN heartattack se retirement income the British were inadequate news of the saving lives are heard it has done that you naked Bond what a discussion can insert when the title of this type of song is in question or waxing or gasing needed I prevent my be personalized number work lace leather and lace work on a flat surface and smooths out this post and a separate system uses a single sirf contained Unity op shop at store holds a good mechanical isliye bad bus figures good Gauhar in late summer curable chairs cabinets chest down house is a set\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "#Try your own voice"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# !pip install SpeechRecognition\n",
    "# !pip install PyAudio\n",
    "import speech_recognition as sr\n",
    "r=sr.Recognizer()\n",
    "\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Please say something\")\n",
    "    audio = r.listen(source)\n",
    "    print(\"Time over, thanks\")\n",
    "    \n",
    "try:\n",
    "    print(\"I think you said: \"+r.recognize_google(audio))\n",
    "except:\n",
    "    pass\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: SpeechRecognition in /Users/akskulka/anaconda3/lib/python3.7/site-packages (3.8.1)\n",
      "Collecting PyAudio\n",
      "Installing collected packages: PyAudio\n",
      "Successfully installed PyAudio-0.2.11\n",
      "Please say something\n",
      "Time over, thanks\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "#code snippet\n",
    "r=sr.Recognizer()\n",
    "\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Please say something\")\n",
    "    audio = r.listen(source)\n",
    "    print(\"Time over, thanks\")\n",
    "    \n",
    "try:\n",
    "    print(\"I think you said: \"+r.recognize_google(audio, language ='hi-IN'))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "except:\n",
    "    pass\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Please say something\n",
      "Time over, thanks\n",
      "Google Speech Recognition could not understand audio\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "raw",
   "source": [
    "Recipe 4-10. Converting Text to Speech"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# !pip install gTTS\n",
    "\n",
    "from gtts import gTTS\n",
    "\n",
    "#chooses the language, English(‘en’)\n",
    "\n",
    "convert = gTTS(text='I like this NLP book', lang='en', slow=False) \n",
    "  \n",
    "# Saving the converted audio in a mp3 file named \n",
    "convert.save(\"audio.mp3\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: gTTS in /Users/akskulka/anaconda3/lib/python3.7/site-packages (2.2.1)\r\n",
      "Requirement already satisfied: requests in /Users/akskulka/anaconda3/lib/python3.7/site-packages (from gTTS) (2.25.1)\r\n",
      "Requirement already satisfied: click in /Users/akskulka/anaconda3/lib/python3.7/site-packages (from gTTS) (7.0)\r\n",
      "Requirement already satisfied: six in /Users/akskulka/anaconda3/lib/python3.7/site-packages (from gTTS) (1.12.0)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/akskulka/anaconda3/lib/python3.7/site-packages (from requests->gTTS) (2.8)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/akskulka/anaconda3/lib/python3.7/site-packages (from requests->gTTS) (3.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/akskulka/anaconda3/lib/python3.7/site-packages (from requests->gTTS) (2019.3.9)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/akskulka/anaconda3/lib/python3.7/site-packages (from requests->gTTS) (1.24.1)\r\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "raw",
   "source": [
    "Recipe 4-11. Translating Speech"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# !pip install goslate\n",
    "import goslate\n",
    "text = \"Bonjour le monde\" \n",
    "gs = goslate.Goslate()\n",
    "translatedText = gs.translate(text,'en')\n",
    "\n",
    "print(translatedText)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting goslate\n",
      "  Using cached https://files.pythonhosted.org/packages/39/0b/50af938a1c3d4f4c595b6a22d37af11ebe666246b05a1a97573e8c8944e5/goslate-1.5.1.tar.gz\n",
      "Collecting futures (from goslate)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/80/f41cca0ea1ff69bce7e7a7d76182b47bb4e1a494380a532af3e8ee70b9ec/futures-3.1.1-py3-none-any.whl\n",
      "Building wheels for collected packages: goslate\n",
      "  Building wheel for goslate (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/akskulka/Library/Caches/pip/wheels/4f/7f/28/6f52271012a7649b54b1a7adaae329b4246bbbf9d1e4f6e51a\n",
      "Successfully built goslate\n",
      "Installing collected packages: futures, goslate\n",
      "Successfully installed futures-3.1.1 goslate-1.5.1\n",
      "Hi world\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "    "
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}